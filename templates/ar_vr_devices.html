<!DOCTYPE html>
<html lang="uk">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AR/VR — Апаратура та ПЗ: Apple Vision Pro • Ray-Ban Meta</title>
  <style>
    :root{
      --bg:#f7f9fb; --card:#ffffff; --accent:#0b5cff; --muted:#6b7280;
      --tile:#ffeeda; --tile2:#e8f0ff;
      --maxw:1100px;
      font-family: Inter, Arial, "Helvetica Neue", sans-serif;
    }
    body{ margin:0; background:var(--bg); color:#111; line-height:1.5;}
    header{ background:#0f1724; color:#fff; padding:28px 12px; text-align:center;}
    header h1{ margin:0; font-size:22px; letter-spacing:0.2px;}
    .container{ max-width:var(--maxw); margin:26px auto; padding:18px;}
    .lead{ color:var(--muted); margin-bottom:16px; text-align:justify;}
    .two-col{ display:grid; grid-template-columns:1fr 1fr; gap:18px; align-items:start;}
    .section-card{ background:var(--card); border-radius:12px; padding:18px; box-shadow:0 6px 18px rgba(11,12,16,0.06);}
    .section-title{ font-size:18px; margin:0 0 8px 0; color:#0b2540;}
    .icons-grid{ display:grid; grid-template-columns:repeat(auto-fill,minmax(180px,1fr)); gap:12px; margin-top:12px;}
    .tile{ background:var(--tile); border-radius:10px; padding:12px; cursor:pointer; min-height:120px; display:flex; flex-direction:column; justify-content:flex-start; transition:transform .16s ease, box-shadow .16s; border:1px solid rgba(0,0,0,0.03);}
    .tile:hover{ transform:translateY(-6px); box-shadow:0 10px 22px rgba(11,12,16,0.08);}
    .tile2{ background:var(--tile2);}
    .tile h3{ margin:0; font-size:15px; color:#072146;}
    .tile p{ margin:8px 0 0 0; font-size:13px; color:var(--muted);}
    .flowchart{ margin-top:10px; display:flex; gap:8px; flex-wrap:wrap;}
    .node{ background:#fff; border-radius:8px; padding:10px; border:1px dashed rgba(11,12,16,0.06); cursor:pointer; min-width:160px;}
    .legend{ font-size:12px; color:var(--muted); margin-top:8px;}
    /* Overlay */
    .overlay{ position:fixed; inset:0; background:rgba(2,6,23,0.6); display:none; align-items:center; justify-content:center; padding:20px; z-index:9999;}
    .overlay-content{ width:min(980px,98%); max-height:86vh; overflow:auto; background:#fff; border-radius:12px; padding:20px; box-shadow:0 20px 60px rgba(2,6,23,0.5); }
    .overlay-title{ font-size:20px; margin:0 0 12px 0; color:#03294a;}
    .overlay-body{ text-align:justify; color:#1b2b3a; }
    .close-btn{ position:fixed; right:22px; top:18px; background:#fff; border-radius:50%; width:38px; height:38px; display:flex; align-items:center; justify-content:center; cursor:pointer; border:1px solid rgba(0,0,0,0.06); box-shadow:0 6px 18px rgba(2,6,23,0.12);}
    .meta-row{ display:flex; gap:12px; flex-wrap:wrap; margin-top:12px;}
    .code-box{ background:#0b1220; color:#bfe1ff; padding:12px; border-radius:8px; font-family:monospace; font-size:12px; }
    footer{ text-align:center; color:var(--muted); margin:22px 0 50px;}
    @media (max-width:900px){ .two-col{ grid-template-columns:1fr; } .tile{ min-height:110px; } }
  </style>
</head>
<body>
  <header>
    <h1>Технічний аналіз: Apple Vision Pro — «просторовий комп’ютер» • Ray-Ban Meta — «AI-окуляри»</h1>
  </header>

  <main class="container">
    <p class="lead">
      Одна сторінка — глибоко і структуровано. Клікніть по будь-якому блоку (він відкриє модальне вікно з детальним технічним описом 8–10 речень).
      Матеріал розраховано на IT-спеціалістів: наведено логічні та фізичні блоки, пайплайни сенсорів, апаратні мікросхеми, ПЗ (OS, драйвери, SDK) та шлях сигналів від середовища до додатку.
    </p>

    <div class="two-col">
      <!-- LEFT: Apple Vision Pro -->
      <section class="section-card" id="apple">
        <h2 class="section-title">Apple Vision Pro — апаратно-програмна архітектура</h2>
        <p style="text-align:justify; color:var(--muted); margin:0 0 12px 0;">
          У цьому блоці — логічні модулі Vision Pro: двочіпова архітектура, підсистема сенсорів, інфраструктура низьколатентного passthrough, оптика та дисплеї, аудіо, енергетика, а також деталі visionOS, SDK та безпеки.
        </p>

        <div class="icons-grid" id="apple-grid">
          <div class="tile" data-id="ap_chip">
            <h3>1. Двочіпова архітектура (M2 + R1)</h3>
            <p>Ролі M2 та R1; обмін даними між ними; де виконується ML-інференс.</p>
          </div>

          <div class="tile tile2" data-id="ap_display">
            <h3>2. Оптична система і дисплеї (micro-OLED, 23M пікселів)</h3>
            <p>як зроблено near-eye дисплей; foveated/retina-aware рендеринг.</p>
          </div>

          <div class="tile" data-id="ap_sensors">
            <h3>3. Камери та сенсори (12 камер, LiDAR, IMU, мікрофони)</h3>
            <p>типи камер та їхні призначення у трекінгу і passthrough.</p>
          </div>

          <div class="tile tile2" data-id="ap_passthrough">
            <h3>4. Пас-тру (photon-to-photon) — pipeline і латентність</h3>
            <p>12 ms, роль R1 у попередній обробці кадрів і синхронізації.</p>
          </div>

          <div class="tile" data-id="ap_tracking">
            <h3>5. Трекінг очей та рук (Optic-ID, IR-камери)</h3>
            <p>як працює eye-tracking, foveation, як відбувається рукопостальовий ввід.</p>
          </div>

          <div class="tile tile2" data-id="ap_audio">
            <h3>6. Аудіосистема — spatial audio та мікрофони</h3>
            <p>HRTF, мікрофонні масиви, аудіо pipeline для просторового звуку.</p>
          </div>

          <div class="tile" data-id="ap_power">
            <h3>7. Енергетика та тепловий дизайн (зовнішній акумулятор)</h3>
            <p>чому батарея зовнішня; теплові обмеження; планування енергоспоживання.</p>
          </div>

          <div class="tile tile2" data-id="ap_mech">
            <h3>8. Корпус, оптичні вставки, підгонка (ZEISS inserts)</h3>
            <p>механіка, матеріали, модульність, кріплення оптики.</p>
          </div>

          <div class="tile" data-id="ap_os">
            <h3>9. Програмне середовище: visionOS, API, мови</h3>
            <p>Swift, RealityKit, ARKit, Metal, SwiftUI — де виконується код.</p>
          </div>

          <div class="tile tile2" data-id="ap_fw">
            <h3>10. Прошивка, драйвери, secure boot та зберігання коду</h3>
            <p>boot chain, Secure Enclave, де лежать образи firmware і як оновлюються.</p>
          </div>

          <div class="tile" data-id="ap_dataflow">
            <h3>11. Потік даних: від сенсора до додатка (по кроках)</h3>
            <p>структурований список кроків: захоплення → обробка → рендер → відтворення.</p>
          </div>
        </div>

        <div class="legend">
          Натисніть блок — побачите докладні пояснення (8–10 речень) технічного рівня.
        </div>
      </section>

      <!-- RIGHT: Ray-Ban Meta -->
      <section class="section-card" id="rayban">
        <h2 class="section-title">Ray-Ban Meta (Ray-Ban AI / Ray-Ban Meta collection) — апаратно-програмна розбивка</h2>
        <p style="text-align:justify; color:var(--muted); margin:0 0 12px 0;">
          Тут розглянуто компактні AI-окуляри (Ray-Ban Meta / Ray-Ban AI): мініатюрні SoC (Qualcomm Snapdragon AR1 Gen1 / подібні), камера(и), мікрофони, аудіо-вивід відкритого типу, мобільна пара—додаток та мета-AI-інтеграція.
        </p>

        <div class="icons-grid" id="rayban-grid">
          <div class="tile" data-id="rb_chip">
            <h3>1. SoC і апаратна платформа (Qualcomm Snapdragon AR1 Gen1)</h3>
            <p>що таке AR1 Gen1, його роль у сенсорній обробці та енергоплануванні.</p>
          </div>

          <div class="tile tile2" data-id="rb_camera">
            <h3>2. Камера(и) — 12 MP ultra-wide / capture pipeline</h3>
            <p>від чого залежить якість знімків, як проходить обробка на платі.</p>
          </div>

          <div class="tile" data-id="rb_audio">
            <h3>3. Аудіо — open-ear speakers, 3–5 мікрофонів, beamforming</h3>
            <p>конструкція open-ear, шумоподавлення, голосовий ввід «Hey Meta».</p>
          </div>

          <div class="tile tile2" data-id="rb_fw">
            <h3>4. Прошивка та мобільний стек (firmware + Meta View app)</h3>
            <p>вбудоване ПЗ на окулярах та його пара з мобільним додатком iOS/Android.</p>
          </div>

          <div class="tile" data-id="rb_ai">
            <h3>5. Meta AI: wake-word, on-device vs cloud, multimodal input</h3>
            <p>як поєднуються локальний інференс та хмарні LLM/сервіси (приклади).</p>
          </div>

          <div class="tile tile2" data-id="rb_privacy">
            <h3>6. Індикація запису, приватність, етичні та технічні захисти</h3>
            <p>LED, апаратні вимикачі, обмеження API для збереження приватності.</p>
          </div>

          <div class="tile" data-id="rb_comm">
            <h3>7. Зв'язок: Bluetooth, Wi-Fi, livestream, протоколи</h3>
            <p>як окуляри підключаються до телефону та хмари; стрімінг у соцмережі.</p>
          </div>

          <div class="tile tile2" data-id="rb_dataflow">
            <h3>8. Потік даних: фото/відео → обробка → інтерфейс користувача</h3>
            <p>етапи компресії, зберігання, синхронізації з мобільним додатком.</p>
          </div>

          <div class="tile" data-id="rb_examples">
            <h3>9. Приклади застосувань і інтеграцій (assistive, social, creator)</h3>
            <p>реальні кейси: live-stream, аудіо-підказки, OCR/скан, допомога слабозрячим.</p>
          </div>
        </div>

        <div class="legend">
          Блоки містять технічні пояснення та ланцюги сигналів. Клікніть для деталей.
        </div>
      </section>
    </div>

    <hr style="margin:22px 0; border:none; border-top:1px solid rgba(11,12,16,0.06);" />

    <section class="section-card">
      <h2 class="section-title">Логічні схеми (короткі): як взаємодіють блоки</h2>

      <div style="display:flex; gap:12px; flex-wrap:wrap; margin-top:12px;">
        <div class="section-card" style="flex:1; min-width:300px;">
          <h3 style="margin:0 0 8px 0;">Vision Pro — спрощений dataflow</h3>
          <div class="flowchart">
            <div class="node" data-id="ap_node_cam">Камери & сенсори</div>
            <div class="node" data-id="ap_node_r1">R1 (reality coprocessor)</div>
            <div class="node" data-id="ap_node_m2">M2 (CPU/GPU/Neural)</div>
            <div class="node" data-id="ap_node_render">Compositor / Metal</div>
            <div class="node" data-id="ap_node_disp">Displays / Optics</div>
          </div>
          <p class="legend">Клік по будь-якому вузлу — детальний опис його ролі в пайплайні.</p>
        </div>

        <div class="section-card" style="flex:1; min-width:300px;">
          <h3 style="margin:0 0 8px 0;">Ray-Ban Meta — спрощений dataflow</h3>
          <div class="flowchart">
            <div class="node" data-id="rb_node_cam">Ultra-wide камера</div>
            <div class="node" data-id="rb_node_soc">Snapdragon AR1 (SoC)</div>
            <div class="node" data-id="rb_node_fw">Firmware + codecs</div>
            <div class="node" data-id="rb_node_phone">Смартфон (Meta View)</div>
            <div class="node" data-id="rb_node_cloud">Meta AI / Cloud</div>
          </div>
          <p class="legend">Покажчик структури передачі кадр→мобільний дод.→хмара.</p>
        </div>
      </div>
    </section>

    <div style="height:20px;"></div>

    <section class="section-card">
      <h2 class="section-title">Короткі техно-нотатки для розробника</h2>
      <div class="meta-row">
        <div style="flex:1; min-width:240px;">
          <strong>Vision Pro — що кодувати</strong>
          <div class="code-box" style="margin-top:8px;">
            <div>Мови: Swift (переважно), Objective-C (усередині фреймворків), Metal shading language.</div>
            <div>Фреймворки: visionOS, RealityKit, ARKit, SwiftUI, Metal, Compositor Services.</div>
          </div>
        </div>
        <div style="flex:1; min-width:240px;">
          <strong>Ray-Ban Meta — увага</strong>
          <div class="code-box" style="margin-top:8px;">
            <div>Firmware: вбудоване C/C++/RTOS або Android-based образ для AR1.</div>
            <div>Моб. app: iOS (Swift) та Android (Kotlin/Java) — обмін контентом та OTA.</div>
          </div>
        </div>
      </div>
    </section>

    <div style="height:30px;"></div>

    <footer>
      © 2025 — Глибокий технічний розбір AR/VR пристроїв — матеріал для IT-спеціалістів. Натисніть на блоки для розширених коментарів.
    </footer>
  </main>

  <!-- Overlay -->
  <div class="overlay" id="overlay" aria-hidden="true">
    <div class="overlay-content" role="dialog" aria-modal="true" aria-labelledby="overlayTitle">
      <h2 id="overlayTitle" class="overlay-title"></h2>
      <div id="overlayBody" class="overlay-body"></div>
    </div>
  </div>
  <button id="closeBtn" class="close-btn" title="Закрити">✖</button>

  <script>
    // Detailed texts (8–10 речень кожен). Тримайте їх тут, прив'язка через id.
    const CONTENT = {
      /* APPLE */
      ap_chip: {
        title: "Двочіпова архітектура — M2 та R1 (огляд ролей)",
        text: [
          "Vision Pro має унікальну двочіпову архітектуру: потужний M2 як головний процесор для запуску visionOS, UI, графіки та важких обчислень, і спеціалізований R1 (reality coprocessor) для реального часу обробки сенсорів.",
          "M2 надає CPU/GPU/Neural Engine для рендерингу сцен, запуску нейромереж та загального виконання додатків; він використовує unified memory для швидкого обміну даними між GPU і Neural Engine.",
          "R1 розроблений для паралельної низьколатентної обробки потоку з камер, сенсорів і мікрофонів — його завдання мінімізувати затримку passthrough і попередньо підготувати дані для M2.",
          "Практично R1 отримує сирі кадри і сенсорні дані, виконує калібрування, синхронізацію часу, попередній фільтр і часткові ML-операції (наприклад, децимація, distorion correction), після чого записує стан у спільну пам’ять.",
          "M2 читає підготовлені R1 дані, виконує фіна-рендеринг (Metal/Compositor) і формує фінальні буфери для micro-OLED дисплеїв.",
          "Такий поділ дозволяє зменшити photon-to-photon latency (Apple вказує на ~12 ms для R1 pipeline), оскільки R1 виконує операції «перед фронтом» рендерингу.",
          "Архітектурно обмін між R1 і M2 здійснюється через високо-пропускну шину та область спільної пам’яті з гарантованою затримкою; це необхідно для синхронізації відео/аудіо та контролю пози.",
          "Із безпекової та оновлювальної точки зору обидва чипи працюють у підписаному екосистемному стеку Apple із secure boot та механізмами OTA оновлень для firmware/прошивок."
        ].join(" ")
      },

      ap_display: {
        title: "Оптика та дисплеї — micro-OLED і 23 мільйони пікселів (технічний бік)",
        text: [
          "Vision Pro використовує пару надщільних micro-OLED панелей, що дають сумарно ~23 мільйони пікселів — більше, ніж 4K-екран для кожного ока, що дозволяє надзвичайну різкість тексту та деталей у ближній зоні.",
          "Micro-OLED як технологія забезпечує високу контрастність та швидке відгуку, критично важливі для зменшення розмиття під час руху голови.",
          "Оптична підсистема складається з мініатюрних лінз/комбінерів і корекційних елементів: завдання — рівномірно доставити зображення на зорове поле користувача, враховуючи різні між-очні відстані та кривизну лінз.",
          "Сумісно з eye-tracking, система може використовувати foveated rendering: рендерити максимальну якість у зоні погляду і віддавати нижчу деталь периферії, економлячи обчислювальні ресурси.",
          "Оптичні вставки для корекції зору (ZEISS) та механічні адаптери дозволяють використовувати пристрій людям із рецептом.",
          "Критично для інженерів — калібрування геометричного викривлення, гармонізація кольорів між двома OLED та корекція хроматичної аберації апаратними/ПЗ-методами.",
          "Рендеринг підлаштовується під фізичні параметри окулярів і дані eye-tracking, щоб уникати візуальних артефактів і зменшити безпекові ризики нудоти.",
          "З точки зору інтеграції, дисплеї підключені до GPU в M2 через високошвидкісний внутрішній інтерфейс, забезпечуючи сумісність з Metal та Compositor Services visionOS."
        ].join(" ")
      },

      ap_sensors: {
        title: "Камери та сенсори — набір і спеціалізації",
        text: [
          "Apple публічно вказує, що Vision Pro має велику кількість камер і датчиків (загалом 12 камер, декілька датчиків глибини/пози та кілька мікрофонів) — кожен з них відповідає за конкретний підзадачі.",
          "Стерео-камери зйомки дають кольоровий passthrough, окремі IR-камери використовуються для eye-tracking і Optic ID (ірис-аутентифікація), а додаткові сенсори — для відстеження навколишньої геометрії та глибини.",
          "LiDAR або time-of-flight сенсор (або його аналог) забезпечує щільну карту глибини, яка використовується для розміщення віртуальних об’єктів у фізичному просторі і покращення occlusion.",
          "IMU (акселерометр + гіроскоп) дає високочастотний інерційний трекінг, необхідний як доповнення до зорових датчиків у випадку швидких рухів голови.",
          "Мікрофонні масиви із beamforming дозволяють виділити голос користувача та подавляти фоновий шум для голосових команд і запису.",
          "Комбінація сенсорів дає redundant (надлишкову) оцінку пози і положення, що критично для точного «якорювання» контенту у просторі.",
          "Сигнали із сенсорів надходять до R1 на попередню фільтрацію й синхронізацію часу, де вони подальше калібруються до спільного world-state для M2.",
          "Для розробника важливо розуміти, що багато сенсорних потоків доступні через ARKit/visionOS data providers у асинхронному режимі, з гарантіями часу та якістю даних."
        ].join(" ")
      },

      ap_passthrough: {
        title: "Passthrough pipeline і latency (photon-to-photon, ≈12 ms)",
        text: [
          "Поняття photon-to-photon latency описує час від захоплення світла камерою до його відтворення на дисплеї — у Vision Pro Apple називає орієнтовне значення ~12 мс у рамках R1 pipeline.",
          "Щоб досягнути такої низької затримки, R1 виконує швидку корекцію кадру, синхронізацію multi-camera, корекцію дисторсії і, можливо, деякі попередні кроки по виявленню ключових об’єктів.",
          "Після попередньої обробки R1 пише дані у область спільної пам’яті, де M2 читає їх і запускає фінальний рендер (з урахуванням UI/3D сцени), після чого кадри подаються на дисплеї.",
          "Ключові оптимізації включають: апаратну синхронізацію таймерів між сенсорами, апаратне калібрування лінз і вбудовані піплайни для де-залежних трансформацій.",
          "Ефективний pipeline дозволяє уникнути несумісності рухів та зображення, що критично для зменшення motion sickness у користувачів.",
          "З інженерної точки зору важливо керувати обсягом даних (компресія, децимація, ROI-crop) ще на етапі R1, щоб M2 отримував тільки релевантну інформацію.",
          "Цей поділ праці також дозволяє паралельне виконання задач: R1 тримає «світовий стан», M2 — візуальну логіку додатків.",
          "Моніторинг latency і jitter в runtime — обов’язкова частина тестування системної інтеграції."
        ].join(" ")
      },

      ap_tracking: {
        title: "Трекінг очей та рук — механіка і застосування",
        text: [
          "Eye-tracking в Vision Pro реалізований через інфрачервоні камери та ML-моделі, що дають дуже точне положення погляду для Optic ID і фовеаційних оптимізацій.",
          "Optic ID — це варіант біометричної ідентифікації, який створює шаблон на основі параметрів ока; ці дані захищені і зберігаються локально в захищеному середовищі пристрою.",
          "Hand tracking використовує RGB/IR камери і моделі комп’ютерного зору для інтерпретації відкритих рук, жестів і вказівок; машинне навчання виділяє ключові точки суглобів пальців.",
          "Комбінація eye+hand tracking дає natural input — погляд для наведення і жест для підтвердження; visionOS надає API для комбінації цих сигналів у події інтерфейсу.",
          "Висока частота оновлення IMU та pre-processing R1 дозволяє зменшувати лаг між жестом і дією інтерфейсу; це особливо важливо для інтерфейсів із доповненою реальністю.",
          "Зі сторони розробника: дані трекінгу поставляються асинхронно, їх потрібно фільтрувати та агрегаувати, враховуючи шум та артефакти від відблисків.",
          "Для безпеки і приватності Optic ID і raw frames не передаються в хмару без явної згоди користувача.",
          "Ретельне калібрування під конкретного користувача забезпечує стабільність інтерфейсу та правильну роботу foveation."
        ].join(" ")
      },

      ap_audio: {
        title: "Аудіосистема — просторове аудіо, мікрофони та pipeline",
        text: [
          "Vision Pro має просторове аудіо, що використовує персоналізовані HRTF-фільтри та позицію голови для стикування віртуального джерела з фізичним простором.",
          "Масив мікрофонів і beamforming дозволяють виділити голос користувача, зменшити фонові шуми та коректно подати інструкції для голосового асистента.",
          "Аудіо-реконструкція в реальному часі інтегрована у загальний pipeline: синхронізація аудіо з латентністю зображення важлива для відчуття реальності.",
          "Апаратні аудіопотоки проходять попередню обробку (AEC, AGC, шумоприглушення) ще до того, як хмарні сервіси чи локальні моделі зможуть їх аналізувати.",
          "Просторове відтворення може використовувати декілька способів: вбудовані динаміки, індивідуальні HRTF, а також канали для зовнішніх навушників/аудіопристроїв.",
          "З боку розробників visionOS надає API для позиціонування звукових джерел та синхронізації їх із відображенням сцен.",
          "Оптимізація кодеку та бітрейту для голосу/медіа важлива для економії пропускної здатності та обчислень.",
          "Тестування spatial audio повинно включати сценарії з різними акустичними умовами та моделями голови користувача."
        ].join(" ")
      },

      ap_power: {
        title: "Енергетика та тепловий дизайн — чому зовнішній акумулятор",
        text: [
          "Apple розміщує батарею зовні (tethered battery), щоб зменшити вагу на голові; офіційні дані говорять про приблизно до 2 годин автономної роботи при портативному використанні.",
          "Зовнішня батарея дозволяє оптимізувати масу і теплоусунення — важливо при розміщенні потужних чипів поблизу обличчя.",
          "Тепловий дизайн headset-а орієнтований на пасивне охолодження корпусу і вивід тепла через раму та посадкові поверхні.",
          "Система керує power-budget динамічно: наприклад, знижує частоти GPU при простому перегляді статичного контенту та підвищує під час intense rendering-навантеження.",
          "Для розробників важлива політика енергоспоживання — слід оптимізувати рендер, уникати непотрібних wake-ups і використовувати foveation.",
          "Фізично батарея містить захист від перевантаження і комунікує зі стрижневими платами через спеціальний роз’єм і протокол зарядки.",
          "Оновлення firmware може впливати на енергетичні профілі, тому виробник надає інструменти для тестування споживання під час розробки.",
          "У проєктуванні інтеграції слід враховувати trade-off між автономністю та температурними обмеженнями, особливо для тривалого використання."
        ].join(" ")
      },

      ap_mech: {
        title: "Механіка та оптичні вставки — матеріали і підгонка",
        text: [
          "Корпус Vision Pro використовує поєднання легких металів та тканин (наприклад Solo Knit Band) для балансу жорсткості і комфорту.",
          "Оптичні вставки (ZEISS optical inserts) кріпляться магнітно — це дозволяє швидко адаптувати пристрій людям із рецептом.",
          "Конструкція передньої панелі приховує камери та сенсори, забезпечуючи при цьому охолодження і естетику; Apple застосовує надточну механіку для мінімізації люфтів.",
          "Підгонка під різні типи обличчя і баланс ваги — критичні задачі, тому застосовуються еластичні ремені та ремені з регулюванням.",
          "Матеріали підбираються з урахуванням довговічності та теплової провідності, щоб уникнути «гарячих зон» при тривалому використанні.",
          "Герметизація важлива для захисту внутрішніх плат і оптики від вологи та пилу, тоді як сервісні порти дають змогу оновлювати батареї та perform maintenance.",
          "З боку інженерів корпус оформлюється із запасом для заміни оптичних блоків і оновлень апаратної частини у майбутньому.",
          "Дизайн також враховує видимість 'EyeSight' — маленький зовнішній дисплей, що показує очі користувача іншим людям."
        ].join(" ")
      },

      ap_os: {
        title: "visionOS, SDK і мови — що використовує розробник",
        text: [
          "visionOS — це операційна система Apple для просторових застосунків; вона побудована на знайомих фреймворках (SwiftUI, ARKit, RealityKit) і дає доступ до Compositor Services та Metal.",
          "Основна мова розробки — Swift; низькорівневі драйвери та частини системи можуть бути в C/Objective-C; shader-и пишуться для Metal Shading Language.",
          "ARKit та RealityKit надають абстракції для сцен, координатних систем, трекінгу та anchor-ів; для високопродуктивних рендерів застосовують Metal 3 та Compositor pipeline.",
          "Apple також надає інструменти для портування ARKit-додатків з iPad/iPhone на visionOS із відповідними адаптаціями вводу та UI.",
          "Додатки для visionOS запускаються у захищеному середовищі з системою дозволів на доступ до сенсорів, камери та Optic ID.",
          "App Store підтримує розповсюдження, а оновлення OTA проходять через підписані образи та механізми безпечного оновлення.",
          "Для оптимізації продуктивності рекомендується використовувати foveated rendering, віртуальні корекції та пакетну обробку подій вводу.",
          "Документація Apple і приклади WWDC дають готові патерни для комбінації gaze+gesture вводу і spatial audio."
        ].join(" ")
      },

      ap_fw: {
        title: "Прошивка, драйвери та де зберігається код (безпека)",
        text: [
          "Низькорівневе ПЗ (bootloader, драйвери пристроїв) зберігається у внутрішній флеш-пам’яті і завантажується через ланцюг довіри (secure boot) з підписаними образами.",
          "Vision Pro, як і інші сучасні пристрої Apple, має механізми апаратної безпеки (Secure Enclave) для захисту біометричних даних (Optic ID) та ключів шифрування.",
          "Драйвери для сенсорів і камер реалізовані у привілейованому просторі (kernel/driver layer) та взаємодіють із user-space runtime через безпечні інтерфейси.",
          "Оновлення firmware від Apple проходять через підписані пакети OTA; системи валідації підпису запобігають установці несанкціонованого коду.",
          "На фізичному рівні бінарні образи займають розділи flash/NVMe (в залежності від конфігурації пам’яті пристрою), а persistent settings шифруються.",
          "Для enterprise-deployment застосовують MDM інструментарій і політики, які теж інтегровані в visionOS для управління апаратними дозволами.",
          "Розробники пристроїв повинні тестувати оновлення на reliability та fail-safe сценарії (повернення до попередньої версії в разі проблем).",
          "Коротко: код «фізично» лежить у внутрішній пам’яті пристрою, підписується виробником і захищається апаратними механізмами та політиками OS."
        ].join(" ")
      },

      ap_dataflow: {
        title: "Потік даних — поетапний список (sensor → app)",
        text: [
          "1) Сировинний захват: камери/мікрофони/IMU записують кадри, аудіопотоки та інерційні дані у свої FIFO.",
          "2) Preprocessing (R1): калібрування кадрів, синхронізація часових штампів, видалення очевидних артефактів і скорочення роздільності, якщо потрібно.",
          "3) World-state fusion: R1 будує попередню 3D-модель навколишньої сцени (feature maps, depth maps) і передає її у спільну пам’ять.",
          "4) App/Rendering (M2): додаток читає world-state, виконує логіку UI/3D, запускає shading pipeline у Metal з урахуванням gaze data.",
          "5) Compositor: фінальний кадр збирається, виконується tone-mapping і підготовка для micro-OLED.",
          "6) Audio: паралельно аудіопотоки синхронізуються, застосовуються HRTF фільтри та spatial mixing.",
          "7) Output: кадри та аудіо відтворюються на дисплеях і динаміках у синхроні; датчики продовжують подавати оновлення.",
          "8) Telemetry/Privacy: логінг/telemetry зберігається локально або передається (за згодою) для аналітики й відладки."
        ].join(" ")
      },

      /* RAY-BAN */
      rb_chip: {
        title: "SoC у Ray-Ban Meta — роль Qualcomm Snapdragon AR1 Gen1 (абстрактно)",
        text: [
          "Нова лінійка Ray-Ban Meta базується на платформі для смарт-окулярів (Qualcomm Snapdragon AR1 Gen1 або подібній архітектурі), яка оптимізована для XR-задач та енергоефективної обробки сенсорних даних.",
          "SoC відповідає за capture pipeline (encode фото/відео), аудіо-обробку, місцевий управлінський firmware і мережеві стек-інтерфейси (Wi-Fi/Bluetooth).",
          "Вбудовані DSP та multimedia блоки виконують кодування H.264/H.265, шумоприглушення і деякий локальний ML-інференс (wake-word, keyword detection).",
          "Платформа спроектована для низького енергоспоживання у вузькому корпусі оправи, із спеціальними режимами sleep/wakeup та апаратними блоками для сенсорів.",
          "Розробники firmware зазвичай використовують C/C++ для низькорівневих модулів, і високорівневі плагіни можуть працювати під Android/RTOS шаром.",
          "Qualcomm надає SDK/stack для обробки мультисензорних потоків та інструментів для інтеграції з мобільними додатками.",
          "SoC також керує зарядом батареї, індикаторами стану та апаратними інтерфейсами для сервісного доступу.",
          "Архітектура SoC у smart-glasses — це компроміс між розміром, продуктивністю кодування і можливістю підключення до хмари."
        ].join(" ")
      },

      rb_camera: {
        title: "Камера(и) у Ray-Ban — ultra-wide 12MP і обробка зображення",
        text: [
          "Ray-Ban Meta рекламуються з однією або декількома ультраширокими 12 MP камерами, оптимізованими під швидку зйомку та соц-функціонал (photo/video, livestream).",
          "Фізично камера мала апертуру, невеликий optical stack та вбудований Image Signal Processor (ISP) у SoC для корекції кольору, шумоприглушення та автоекспозиції.",
          "Після захоплення кадру ISP робить демозаїку, баланс білого, sharpening, а потім може виконувати додатковий ML-пост-процесинг (стабілізація, frame interpolation).",
          "Кадри можуть зберігатися на носії окулярів або стрімитись у мобільний додаток і далі в хмару (streaming pipeline має конвертацію та адаптацію бітрейту).",
          "Через обмеженість енергії і простору часто застосовують режим burst або 1080p video з оптимальнішими налаштуваннями для соцмереж.",
          "Контроль індикації запису (hardware LED) і фізичний апаратний перемикач — це важливі елементи для прозорості щодо того, коли ведеться запис.",
          "Якість кадрів залежить від оптики оправи і алгоритмів ISP/ML, тому тестування для різних умов освітлення є критичним.",
          "Інженерна інтеграція камери з SoC — це справжній виклик miniaturization + heat + bandwidth."
        ].join(" ")
      },

      rb_audio: {
        title: "Аудіо в Ray-Ban — open-ear speakers, мікрофони, beamforming",
        text: [
          "Ray-Ban Meta використовують open-ear (open-ear) аудіо — мініатюрні динаміки у дужках, що дають змогу чути зовнішній світ і одночасно прослуховувати контент.",
          "Мікрофонні масиви (3–5 мікрофонів) забезпечують beamforming для виділення голосу користувача та зменшення фонових шумів під час дзвінків і голосових команд.",
          "Аудіо pipeline на SoC виконує AEC (echo cancellation), AGC (автоматичну керовану гучність) та шумозаглушення до передачі у додаток чи хмару.",
          "Open-ear дизайн ставить додаткові вимоги до дизайну акустичної камери, щоб забезпечити достатній бас і ясність без вкриття вуха.",
          "Вбудовані профілі для комунікацій і музики дозволяють балансувати між якістю звуку і енергоспоживанням.",
          "За потреби аудіопотоки можуть передаватись у мобільний додаток для подальшої обробки або стрімінгу.",
          "Важливо проводити тестування на різних вухах і умовах оточення, оскільки open-ear звук сильно залежить від посадки оправи.",
          "Підтримка просторового звуку обмежена апаратними можливостями, але частина просторових функцій може бути реалізована через мобільний софт."
        ].join(" ")
      },

      rb_fw: {
        title: "Прошивка та мобільний стек — firmware + Meta View (пара)",
        text: [
          "Окуляри працюють у тісній парі з мобільним додатком (Meta View / Meta app), який служить UI для налаштувань, збереження кадрів і оновлень firmware.",
          "На боці окулярів працює компактний firmware, який керує сенсорами, кодеками, живленням і базовими ML-завданнями (наприклад, wake-word).",
          "Мобільний додаток реалізований на iOS/Android і використовує Bluetooth/Wi-Fi для синхронізації, стрімінгу та віддаленого управління.",
          "OTA оновлення firmware передаються через додаток або напряму, і підписані пакети гарантують цілісність образів.",
          "Firmware часто підготовлений на C/C++ і працює або над легким RTOS, або у модифікованому Android-ядрі, залежно від платформи.",
          "Архітектура передбачає розмежування відповідальностей: окуляри — capture/encode/low-level, смартфон — UI/Cloud gateway/LLM bridge.",
          "У практиці це дає зручний UX: обробка важкої логіки у хмарі/смартфоні, мінімум latency для wake-word локально.",
          "Розробникам треба тестувати сумісність прошивки з різними версіями мобільних ОС та сценаріями без підключення до мережі."
        ].join(" ")
      },

      rb_ai: {
        title: "Meta AI — wake-word, on-device inference і хмарна інтеграція",
        text: [
          "Ray-Ban Meta підтримують голосову активацію («Hey Meta») — wake-word обробляється локально для швидкої реакції та економії трафіку.",
          "Після активації системи відправляють запит на Meta AI: частина обчислень може виконуватись у хмарі (LLM, генерація відповідей), а деякі мультимодальні попередні опрацювання — на пристрої або смартфоні.",
          "Використання локального inference (на SoC або DSP) для базових команд знижує затримку і забезпечує приватні операції без доступу до мережі.",
          "Мультиформатне введення (зображення + голос) дозволяє розв’язувати завдання комп’ютерного зору: опис сцени, OCR, переклад у реальному часі.",
          "Crytical point — latency на шляху read→inference→reply: для деяких сценаріїв Meta використовує гібридний підхід: локальний predications + хмарний контекст.",
          "Комунікація з хмарою шифрується, а великі моделі виконуються на серверах Meta/партнерів; це дає потужність при обмеженій енергії окулярів.",
          "З точки зору безпеки, приватність multimodal data контролюється політиками додатку і згодою користувача.",
          "Розробникам доступні SDK та інтерфейси для інтеграції функцій Meta AI у власні сервіси/eyes-apps."
        ].join(" ")
      },

      rb_privacy: {
        title: "Приватність та індикація запису — апаратні і софт-механізми",
        text: [
          "Ray-Ban має апаратну індикацію запису (LED) і апаратні перемикачі для вимкнення камери, що покликані підвищити прозорість дій окулярів для оточення.",
          "Meta також запроваджує програмні обмеження API, щоб третім додаткам було складніше непомітно збирати дані без повідомлення користувачів.",
          "Проте існують загальні занепокоєння: маленький розмір індикаторів і можливі способи їх обходу викликають етично-правові дискусії.",
          "Технічно варто проектувати системи так, щоби 'recording' флаг був апаратно примусово встановлений у read-only регіоні, що ускладнює модифікації стороннім ПЗ.",
          "Крім апаратних рішень, потрібні політики доступу, журнали дій та UI покликання, що показують поточний режим роботи окулярів.",
          "Для enterprise-використання потрібно забезпечити MDM-політики і контроль доступу, а для research — механізми анонімізації даних.",
          "Інженерам важливо передбачити audit trails та механізми віддаленого видалення/зашифрування чутливих даних.",
          "Юридичні та етичні норми щодо запису у публічних місцях впливають на дизайн функціоналу і доступності деяких можливостей."
        ].join(" ")
      },

      rb_comm: {
        title: "Зв'язок і стрімінг — Bluetooth, Wi-Fi та livestream архітектура",
        text: [
          "Окуляри підключаються до смартфону через Bluetooth для управлінських команд і через Wi-Fi для великих потоків даних (відео стріму, OTA), залежно від сценарію.",
          "Live-streaming реалізовано як pipeline: capture → encode (H.264/H.265) → transport (RTMP/HTTPS) через мобільний інтернет або Wi-Fi.",
          "Bluetooth LE використовується для low-bandwidth sync (battery state, notifications), тоді як Wi-Fi дає пропускну здатність для відео у високій якості.",
          "Протоколи забезпечують adaptive bitrate, щоб підтримувати якість при змінних умовах мережі та економити батарею.",
          "Для realtime функцій (дзвінки, AR-collab) потрібні low-latency канали і оптимізовані сервіси у хмарі/edge.",
          "Безпека з’єднань реалізована через TLS/VPN-подібні шари та аутентифікацію пристроїв через мобільний додаток.",
          "Інфраструктура повинна передбачати fallback-сценарії, коли мобільного зв’язку немає — збереження локальної копії до синхронізації.",
          "Розробникам слід тюнінгувати кодеки й організовувати тестування у реальних мережевих умовах."
        ].join(" ")
      },

      rb_dataflow: {
        title: "Потік даних у Ray-Ban — від фото до хмари (коротко)",
        text: [
          "1) Захоплення: камера робить кадр/відео, ISP здійснює первинну обробку і передає дані до SoC.",
          "2) Локальна обробка: DSP виконує AEC/AGC, wake-word detection і прості ML-задачі.",
          "3) Компресія/encode: відео кодується апаратними блоками для мінімізації енергоспоживання.",
          "4) Транспорт: кадри передаються на смартфон (через Wi-Fi/Bluetooth) або відразу стрімляться у хмару з мобільного гейту.",
          "5) Хмарна обробка: великі ML-моделі виконується у хмарі (Meta AI) для multimodal answers чи аналізу зображення.",
          "6) UI: мобільний додаток синхронізує дані і показує історію, керування та sharing controls.",
          "7) Збереження: фото/відео зберігаються локально та/або у хмарі залежно від налаштувань користувача.",
          "8) Telemetry/OTA: дані телеметрії допомагають у діагностиці та оновленнях firmware."
        ].join(" ")
      },

      rb_examples: {
        title: "Приклади застосувань — де smart-glasses дають практичну цінність",
        text: [
          "Live-stream для креаторів: hands-free зйомка POV контенту та одночасний стрім у соцмережі з мінімальною латентністю.",
          "Помічник для слабозрячих: OCR та опис сцени у режимі реального часу за допомогою AI, який підказує об’єкти й текст голосом.",
          "Службові сценарії: експерт-інструктажи (ремонтні роботи), де технік передає відео супервайзеру і отримує поради в реальному часі.",
          "Переклад і розпізнавання мов: live субтитри та голосові підказки в режимі реального часу.",
          "Асист у шопінгу/туризмі: об’єкти розпізнаються і дається контекст (ціни, історія), що робить hands-free UX корисним для повсякдення.",
          "Creator tools: швидка обробка кадрів на мобільному додатку і інтеграція з соцмережами для негайного публікування.",
          "Інтеграція з AR сервісами: інтерактивні підказки поверх реальної сцени (QR-скан, навігація всередині приміщення).",
          "Усі кейси вимагають балансування latency, privacy і енергоспоживання — архітектурні рішення мають враховувати це компромісно."
        ].join(" ")
      },

      /* Nodes (flowchart clickable nodes) */
      ap_node_cam: {
        title: "Node: Камери & сенсори (вузол у схемі)",
        text: [
          "Цей вузол агрегує всі оптичні та інерційні сенсори: RGB-камери, IR-камери, LiDAR/ToF, IMU і мікрофони.",
          "Він формує перші буфери з сировими даними, додає часові штампи і виконує мінімальні локальні prefilters.",
          "Після цього дані синхронізуються і передаються на R1 для подальшої обробки та world-state fusion.",
          "Камери служать як для passthrough, так і для побудови 3D-карти оточення; IR-камери — для eye-tracking.",
          "Інженери повинні контролювати exposure, fps та затримку буфера, щоб уникнути несумісностей в pipeline.",
          "Підключення кожного сенсора реалізовано через спеціалізовані інтерфейси (MIPI, I2C для датчиків), що потребує відповідних драйверів.",
          "Цей вузол також має hardware-led індикацію стану захоплення і механізми захисту приватності.",
          "Важливо: різні сенсори працюють на різних частотах та мають різну роздільну здатність — їх треба узгоджувати."
        ].join(" ")
      },

      ap_node_r1: {
        title: "Node: R1 — reality coprocessor (вузол у схемі)",
        text: [
          "R1 — призначений для обробки сенсорних потоків у реальному часі; його мета — мінімізувати latency між камерами й дисплеєм.",
          "Він виконує калібрування, вирівнювання кадрів, дисторційну корекцію, первинне compaction і можливі ML-етапи для прискорення.",
          "R1 пише world-state у спільну пам’ять, формуючи стабільний snapshot для M2, який вже робить application-level рендеринг.",
          "Цей вузол критичний для стабільної передачі інформації про положення користувача і об’єктів сцени.",
          "Архітектурно R1 тісно пов’язаний з камерами, IMU і мікрофонами, і має гарантії часу обробки (real-time constraints).",
          "Він також відповідає за апаратну синхронізацію часових штампів сенсорів (hw timestamping).",
          "R1 має свій firmware і механізми оновлення, але керується через загальний OS-стек пристрою.",
          "Оптимізація R1 дає значний виграш у latency і відчутті 'present' для користувача."
        ].join(" ")
      },

      ap_node_m2: {
        title: "Node: M2 — compute, UI, Neural Engine (вузол)",
        text: [
          "M2 — головний апаратний блок, що обробляє UI-логіку, великий ML-інференс, рендеринг у Metal та взаємодію з visionOS.",
          "GPU та Neural Engine M2 застосовуються для shading, compositing та складних нейронних завдань, що потребують високого throughput.",
          "M2 читає world-state від R1 і виконує фінальний рендер, UI transitions і системні сервіси visionOS.",
          "Він також управляє апаратними ресурсами, scheduler-ом задач і виконує підготовку кадрів для дисплеїв.",
          "З системної точки зору M2 працює з unified memory та high-bandwidth шиною для швидкої взаємодії з пам’яттю дисплеїв.",
          "Доступ до M2 мають лише підписані процеси та сервіси в рамках політик visionOS, що підвищує безпеку.",
          "M2 також опрацьовує persistent storage і виконує криптографічні операції у співпраці з Secure Enclave.",
          "Оптимізація додатків під M2 — ключ до хорошого UX і довгої автономності."
        ].join(" ")
      },

      ap_node_render: {
        title: "Node: Compositor / Metal (вузол)",
        text: [
          "Compositor — це компонент, що збирає шари (UI, 3D-сцена, passthrough) у фінальний кадр для дисплея.",
          "Він виконує тональні перетворення, gamma-correction, antialiasing і підготовку для панелей micro-OLED.",
          "Metal API забезпечує низькорівневий контроль за шейдерами і буферами, що критично для продуктивного рендерингу.",
          "Compositor також враховує дані eye-tracking для foveated rendering та динамічного LOD.",
          "Цей вузол повинен мінімізувати CPU/GPU синхронізацію (зведення sync points) для кращої продуктивності.",
          "Важливі аспекти: double buffering, render pass оптимізації, pipeline caching та resource residency.",
          "Для розробників Apple дає патерни для інтеграції Metal-рендерів з Compositor Services visionOS.",
          "Коректна робота Compositor-а напряму впливає на якість passthrough і комфорт користувача."
        ].join(" ")
      },

      ap_node_disp: {
        title: "Node: Displays / Optics (вузол у схемі)",
        text: [
          "Цей вузол відповідає за остаточну подачу пікселя до ока: він отримує frame buffer, застосовує правильну геометричну трансформацію і відправляє сигнал на micro-OLED.",
          "Оптика перетворює мініатюрні пікселі візуальної поверхні у загальне зображення, вирішуючи питання фокусної дистанції та аберацій.",
          "Калібрування під кожне око та підключення оптичних вставок — прерогатива цього шару.",
          "Дисплейний вузол також контролює refresh rate та синхронізацію з вхідними датчиками, щоб уникнути tearing та mismatch.",
          "Через обмежену пропускну здатність інтерфейсів дисплеїв потрібна компресія/packing для прискорення доставки кадрів.",
          "Для інженерів важливо відслідковувати gamut, color depth та latency на цьому етапі.",
          "Невелика апаратна несумісність тут легко створює відчуття дискомфорту або спотворень.",
          "Тому дизайн дисплей-інтерфейсу та оптики — критичні елементи системної інтеграції."
        ].join(" ")
      },

      ap_node_cam: { /* duplicate key prevented above */ }
    };

    // Attach click handlers to tiles and nodes
    function openOverlay(id){
      const content = CONTENT[id];
      if(!content) return;
      const overlay = document.getElementById('overlay');
      document.getElementById('overlayTitle').textContent = content.title || '';
      document.getElementById('overlayBody').innerHTML = '<p>' + content.text.replace(/\\n/g,'</p><p>') + '</p>';
      overlay.style.display = 'flex';
      document.getElementById('closeBtn').style.display = 'flex';
      overlay.setAttribute('aria-hidden','false');
    }

    function closeOverlay(){
      const overlay = document.getElementById('overlay');
      overlay.style.display = 'none';
      document.getElementById('closeBtn').style.display = 'none';
      overlay.setAttribute('aria-hidden','true');
      document.getElementById('overlayTitle').textContent = '';
      document.getElementById('overlayBody').innerHTML = '';
    }

    // add listeners
    document.querySelectorAll('.tile, .node').forEach(el=>{
      el.addEventListener('click', ()=>{
        const id = el.getAttribute('data-id');
        if(id) openOverlay(id);
      });
    });

    document.getElementById('closeBtn').addEventListener('click', closeOverlay);
    // Close on clicking outside content
    document.getElementById('overlay').addEventListener('click', function(e){
      if(e.target === this) closeOverlay();
    });

    // keyboard escape
    document.addEventListener('keydown', (e)=>{ if(e.key === 'Escape') closeOverlay(); });

    // ensure close button hidden initially
    document.getElementById('closeBtn').style.display = 'none';
  </script>

  <!--
    Джерела (основні опорні факти, які використані при підготовці матеріалу):
      - Apple Vision Pro — офіційна сторінка та огляд: dual-chip (M2 + R1), 12 cameras / sensors / microphones, photon-to-photon latency, micro-OLED 23M pixels. :contentReference[oaicite:0]{index=0}
      - visionOS (документація для розробників, ARKit у visionOS, WWDC матеріали). :contentReference[oaicite:1]{index=1}
      - Ray-Ban Meta (офіційний опис): ultra-wide 12 MP camera, 5-mic system, «Hey Meta», livestreaming можливості. :contentReference[oaicite:2]{index=2}
      - Qualcomm — Snapdragon AR1 Gen1 (платформа для smart-glasses / AR). :contentReference[oaicite:3]{index=3}
      - Apple security / Secure Enclave та secure boot (практики захисту платформ Apple). :contentReference[oaicite:4]{index=4}
    Примітка: частина описів (особливо щодо внутрішніх оптимізацій і пайплайнів) — технічно виведені з офіційних джерел + загальних архітектурних патернів у XR-індустрії. Для конкретних апаратних ревізій (версії SoC у конкретній моделі окулярів) перевіряйте специфікацію виробника.
  -->

</body>
</html>
